{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zoom grader for Biosem\n",
    "\n",
    "Unlike Piazza-grader, doesn't work with Piazza, but looks at google forms with questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = '../../data/attendance/'\n",
    "target_meeting = 'Biosem' # Options: {'Biosem', 'Comput', 'Neuro'}\n",
    "chat_mask = 'Biosem'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Zoom logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read attendance data\n",
    "\n",
    "df = pd.DataFrame()\n",
    "file_list = os.listdir(folder_name)\n",
    "print(\"Total files: \",len(file_list))\n",
    "\n",
    "processed_set = set()\n",
    "processed_dict = {}\n",
    "for fname in file_list:\n",
    "    if fname[-3:]!='csv':\n",
    "        continue # Ignore everything that is not a csv\n",
    "    fullname = folder_name + fname\n",
    "    header = pd.read_csv(fullname, header=0, nrows=1) # Attempt to read the header\n",
    "    if 'Topic' not in header.columns: # Not a zoom log, skip this one\n",
    "        continue\n",
    "    name = header['Topic'][0]    \n",
    "    datestring = header['Start Time'][0][:10]\n",
    "    if name+datestring in processed_set:\n",
    "        print(f\"Duplicated meeting: {name+datestring} ({fname}) already saved as {processed_dict[name+datestring]}\")\n",
    "        continue  # This meeting\n",
    "    processed_set.add(name+datestring)\n",
    "    processed_dict[name+datestring] = fname\n",
    "    \n",
    "    data = pd.read_csv(fullname, header=2)\n",
    "    data['Date'] = datestring\n",
    "    data['Meeting'] = name\n",
    "    data['User Email'] = data['User Email'].fillna('none') # NaNs are ignored by aggregation below\n",
    "    \n",
    "    # Join Time\tLeave Time\tDuration (Minutes)\n",
    "    if 'Join Time' in data.columns:  # Wrong output format - it is sometimes unavoidable\n",
    "        data['Total Duration (Minutes)'] = data['Duration (Minutes)']\n",
    "        data = data.drop(columns=['Join Time', 'Leave Time', 'Duration (Minutes)'])\n",
    "    \n",
    "    df = df.append(data, ignore_index=True)\n",
    "\n",
    "print('Meeting files:', len(processed_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename fields, standardize meetings that had synonyms\n",
    "\n",
    "df= df.rename({'User Email': 'email', \n",
    "               'Total Duration (Minutes)': 'minutes', \n",
    "               'Name (Original Name)': 'name',\n",
    "               'Meeting':'meeting',\n",
    "               'Date':'date'}, axis=1)\n",
    "meeting_dict = {'Biosem Zoom': 'Biosem', \n",
    "                'Biosem_spring_2021': 'Biosem',\n",
    "                'Neuroscience': 'Neuro',\n",
    "                'Computational Neuro': 'Comput'}\n",
    "df['meeting'] = df['meeting'].replace(meeting_dict)\n",
    "df.name = df.name.str.title()  # Capitalize names (for consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inexplicably, some total participation counts are stored as strings, not numbers. Correct that.\n",
    "\n",
    "df.loc[df.minutes=='Yes'] = 0 # No idea what it means, but Zoom outputed it!\n",
    "df.minutes = df.minutes.astype(int)\n",
    "df = df[df.minutes>0]  # Remove weird empty entries\n",
    "\n",
    "# Full attendance and late classes:\n",
    "df['check'] = 0.3*(df.minutes>30) + (1-0.3)*(df.minutes>40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What meetings are even there?\n",
    "set(df.meeting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participation length histogram\n",
    "if False:\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.subplot(121)\n",
    "    plt.hist(df.loc[df.meeting=='Biosem'].minutes.values, bins=50);\n",
    "    plt.title('Biosem');\n",
    "    plt.subplot(122)\n",
    "    plt.hist(df.loc[df.meeting=='Neuro'].minutes.values, bins=50);\n",
    "    plt.title('Neuro');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only analyze one type of meetings starting from here\n",
    "df = df[df.meeting==target_meeting]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the actual list of students. Note that the file name needs to match the meeting name.\n",
    "\n",
    "people = pd.read_csv(folder_name + target_meeting + '.csv', header=0, sep=',')\n",
    "people.columns = [' '.join(s.split()) for s in people.columns] # Remove repeating spaces, just in case\n",
    "# print(people.columns)\n",
    "people['name'] = people['FIRST NAME'] + ' ' + people['LAST NAME']\n",
    "people = (people\n",
    "          .drop_duplicates() # A left-over from the \"All meetings at once\" pipeline, but let's keep for a while\n",
    "          .reset_index()\n",
    "          .rename({'ID#':'id', 'Email': 'email'}, axis=1)\n",
    "          .loc[:,['id', 'email', 'name']]\n",
    "         )\n",
    "print(people.columns)\n",
    "# people.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Troubleshooting: A full list of meetings with their attendance.\n",
    "# Check if the plot makes sense.\n",
    "\n",
    "dfm = df.groupby(['date','meeting','name']).agg({'minutes': sum})\n",
    "dfm.minutes = 1*(dfm.minutes>10)\n",
    "dfm = dfm.groupby(['date', 'meeting']).agg({'minutes': sum}).reset_index()\n",
    "dfm = dfm.rename({'minutes':'people'}, axis=1)\n",
    "dfm.date = pd.to_datetime(dfm.date)\n",
    "print(\"Meetings so far:\", dfm.shape[0])\n",
    "\n",
    "plt.figure(figsize=(9,2))\n",
    "plt.plot(dfm.date.dt.dayofyear, dfm.people, '.');\n",
    "plt.xlabel('Meeting');\n",
    "plt.ylabel('People');\n",
    "\n",
    "# print(dfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any entries without email at all\n",
    "df[[len(a)<10 for a in df.email]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and process known alts\n",
    "\n",
    "df_alts = pd.read_csv(folder_name + 'alts.csv', header=0, sep=',')\n",
    "\n",
    "# First find official emails where available, and drop some users manually (e.g. the instructor)\n",
    "df_fixed = (df\n",
    "            .merge(df_alts, on='email', how='left', suffixes=['', '_r'])\n",
    "            .drop(columns=['name_r'])\n",
    "            .query(\"real_email != 'none'\")\n",
    "           )\n",
    "\n",
    "# Substitute 'wrong' emails with 'official' emails where available\n",
    "ind = (df_fixed.real_email.notna())\n",
    "df_fixed.loc[ind, 'email'] = df_fixed.loc[ind, 'real_email']\n",
    "df_fixed = df_fixed.drop(columns='real_email')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find people with emails that aren't on the official list\n",
    "# Output them, to manually create a list of alt-emails (that will be )\n",
    "\n",
    "df_lost = (df_fixed           \n",
    "           .groupby(['name','email'])\n",
    "           .agg({'minutes': sum})\n",
    "           .reset_index()\n",
    "           .merge(people, on='email', how='left', suffixes=['', '_r']) # Ignore official name (_r)\n",
    "           .drop(columns='name_r')           \n",
    "           .query('id.isna()', engine='python') # Only keep unrecognized users\n",
    "          )\n",
    "print('Unrecognized emails (uncomment to see the list):', len(df_lost.id))\n",
    "\n",
    "# Output nice human-readable form:\n",
    "df_lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real name searher:\n",
    "token='jerrdd'\n",
    "df_fixed.query('name.notna()', engine='python').query('name.str.lower().str.contains(@token)', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fixed.fillna(' ').query(\"email.str.contains('6406')\", engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lookup correct names, and drop all users who are not on bip\n",
    "df_fixed = (df_fixed\n",
    "            .merge(people, on='email', how='left', suffixes=['_l', '']) # This time keep official names only\n",
    "            .drop(columns=['name_l', 'id', 'Guest'])\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a summary\n",
    "\n",
    "dfs = (df_fixed\n",
    "       .groupby(['name','email'])\n",
    "       .agg({'check': sum})\n",
    "       .reset_index()\n",
    "       .sort_values(by='check')\n",
    "      )\n",
    "\n",
    "#dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Google responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_folder_name = folder_name + 'biosem_questions/'\n",
    "\n",
    "df_responses = pd.DataFrame()\n",
    "file_list = os.listdir(full_folder_name)\n",
    "print(\"Total files: \",len(file_list))\n",
    "\n",
    "for fname in file_list:    \n",
    "    fullname = full_folder_name + fname    \n",
    "    date = ' '.join(fullname.split(' ')[2:4])[:-1] + ' 2021, 12:10 pm'\n",
    "    # print(date)\n",
    "    \n",
    "    df_temp = pd.read_excel(fullname).iloc[:,:-1]\n",
    "    df_temp.columns = ['timestamp', 'email']\n",
    "    df_temp = (df_temp\n",
    "               .groupby('email')\n",
    "               .agg({'timestamp':'min'})\n",
    "               .reset_index()\n",
    "              )\n",
    "    df_temp['date'] = date\n",
    "    df_responses = df_responses.append(df_temp)\n",
    "    \n",
    "#print('Total lines:', df_responses.shape[0])\n",
    "df_responses.date = pd.to_datetime(df_responses.date)\n",
    "df_responses['good'] = df_responses.timestamp < df_responses.date\n",
    "df_responses['late'] = (df_responses.timestamp - df_responses.date)\n",
    "df_responses.email = df_responses.email.str.lower()\n",
    "df_responses.late = np.maximum(0, df_responses.late.dt.days*24*60 + np.round(df_responses.late.dt.seconds/60)).astype(int)\n",
    "\n",
    "df_responses = (df_responses\n",
    "                .reset_index()\n",
    "                .drop(columns='index')\n",
    "               )\n",
    "#df_responses.head(5)\n",
    "\n",
    "ind = np.argwhere(df_responses.email.str[-4:].str.match('bard').values)[0]\n",
    "df_responses.loc[ind, 'email'] = df_responses.email[ind].str.replace('bard', 'bard.edu')\n",
    "df_responses.email = df_responses.email.str.replace('gmail.com', 'bard.edu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unrecognized emails\n",
    "(df_responses\n",
    " .groupby('email')\n",
    " .agg({'good':'sum'})\n",
    " .reset_index()\n",
    " .merge(dfs, on='email', how='left')\n",
    " .query(\"check.isna()\", engine='python')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions that were submitted late\n",
    "(df_responses\n",
    " .query('not good') \n",
    " .merge(dfs[['email','name']], on='email')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final summary grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Full output\n",
    "\n",
    "df_full = (df_responses\n",
    "           .groupby('email')\n",
    "           .agg({'good':'sum'})\n",
    "           .merge(dfs, on='email') \n",
    "           .assign(passed = (df_full.check>=13-1-3) & (df_full.good >= 13-2-3))           \n",
    "          )\n",
    "# No info about RNA seminar, so -1\n",
    "# First and last seminar there were no questions, so -2\n",
    "# 3 seminars can be missed, so -3 in both cases\n",
    "\n",
    "# Show the full giant thing:\n",
    "with pd.option_context('display.max_rows', 14000, 'display.width', 1000):\n",
    "    # print(df_full)\n",
    "    pass\n",
    "\n",
    "df_full.sort_values('passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Students who didn't submit enough questions\n",
    "df_full.query('good<13-2-3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze one student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check individual records of needed\n",
    "token = 'Cree'\n",
    "\n",
    "# Full attendance:\n",
    "all_meetings = df.groupby('date').agg({'name':'count'}).reset_index()\n",
    "partial = df.loc[df.name.str.contains(token)]\n",
    "out = all_meetings[['date']].merge(partial, on='date', how='left')[['date','name','email','minutes','check']]\n",
    "out.loc[out.check.isna(),'check'] = 0\n",
    "print(sum(out.check))\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All homeworks:\n",
    "df_responses[df_responses.email.str.contains('3431')].sort_values('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mid-term letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(df_full, df_piazza, i):\n",
    "    # Write a full response for one student\n",
    "    \n",
    "    sec = df_full.iloc[i]\n",
    "    name = sec.name_piazza\n",
    "    \n",
    "    flag_submitted_something = False\n",
    "    if name in df_piazza.name.unique():\n",
    "        flag_submitted_something = True\n",
    "        missing_work = (df_piazza\n",
    "                        .groupby(['work', 'name'])\n",
    "                        .agg({'message':'count'})\n",
    "                        .reset_index()\n",
    "                        .pivot_table(index='work', columns='name', values='message')\n",
    "                        .reset_index()\n",
    "                        [['work', name]]\n",
    "                        .set_axis(['work', 'name'], axis=1, inplace=False)\n",
    "                        .query('name.isna()', engine='python')\n",
    "                        .work\n",
    "                        .sort_values()\n",
    "                        .tolist()\n",
    "                     )\n",
    "    \n",
    "    def remove_double_spaces(s):\n",
    "        s = s.replace('\\n', ' ')\n",
    "        return ' '.join([c for c in s.split(' ') if c])\n",
    "    \n",
    "    print(f\"{sec.name_zoom} {sec.email}:\")\n",
    "    print(f\"Dear {sec.name_piazza.split()[0]},\")\n",
    "    print(f\"based on my records as of {max(df.date)}\")\n",
    "    print(f\"you have attended {np.round(sec.check).astype(int)} classes \", end='')\n",
    "    print(f\"(out of {classes_so_far} that we had so far), \")\n",
    "    print(f\"and submitted {sec.total} homeworks (out of {works_so_far} that we had)\")   \n",
    "    if sec.good>0:\n",
    "        print(f\"{sec.good} of these homeworks were really good!! (and others were also fine :)\")\n",
    "    if sec.total < works_so_far and flag_submitted_something:\n",
    "        print(f\"\\n(Works that are missing: {'; '.join(missing_work)})\\n\")\n",
    "    print(f\"You were active in {sec.n_chats} class sessions\", end='')\n",
    "    if sec.percentile_chats<50:\n",
    "        print(f\", which places you in the top {sec.percentile_chats}%\", end='')\n",
    "    else:\n",
    "        print(f\", which places you in the bottom {100-sec.percentile_chats}%\", end='')\n",
    "    print(\" in terms of class participation.\")\n",
    "    \n",
    "    print(f\"Taking all of it into account, your current automatically projected grade is \", end='')\n",
    "    if sec.grade=='B': print('between B and B+')\n",
    "    elif sec.grade=='B+': print('between B+ and A-')        \n",
    "    else: print(sec.grade)\n",
    "    \n",
    "    if sec.grade in {'F', 'C'}:\n",
    "        message = \"\"\"If you want to improve, you can submit missing homeworks. \n",
    "              For missed lab work, just do the lab, and submit your work, as described in the assignment. \n",
    "              For missed questions, at this point the assignment is a bit different.\n",
    "              You will need to answer the following question: \n",
    "              'What is the most interesting thing that you learned that week, and what makes it interesting for you?'. \n",
    "              I would expect about a paragraph of text, with explicit references to what you learned from \n",
    "              home assignments, and from our class discussions. Additional sources are also welcome!\"\"\"\n",
    "        print('\\n'+remove_double_spaces(message))\n",
    "    print(\"\\n(If anything about this summary does not ring right to you, please email me, \" \\\n",
    "          \"and I'll double-check my records!)\")\n",
    "        \n",
    "response(df_full, df_piazza, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.where(df_full.name_piazza.str.match('Ste'))[0][0]\n",
    "print(i)\n",
    "response(df_full, df_piazza, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(df_full.shape[0]):\n",
    "    response(df_full, df_piazza, i)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ouput the summary csv\n",
    "#recognized.to_csv(folder_name + '../attendance_summary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
