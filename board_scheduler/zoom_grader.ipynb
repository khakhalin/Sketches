{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zoom grader\n",
    "\n",
    "Loads zoom reports from a pre-defined folder, and calculates attendance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = '../../data/attendance/'\n",
    "target_meeting = 'Neuro' # Options: {'Biosem', 'Comput', 'Neuro'}\n",
    "chat_mask = 'Neuroscience'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Zoom logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read attendance data\n",
    "\n",
    "df = pd.DataFrame()\n",
    "file_list = os.listdir(folder_name)\n",
    "print(\"Total files: \",len(file_list))\n",
    "\n",
    "processed_set = set()\n",
    "processed_dict = {}\n",
    "for fname in file_list:\n",
    "    if fname[-3:]!='csv':\n",
    "        continue # Ignore everything that is not a csv\n",
    "    fullname = folder_name + fname\n",
    "    header = pd.read_csv(fullname, header=0, nrows=1) # Attempt to read the header\n",
    "    if 'Topic' not in header.columns: # Not a zoom log, skip this one\n",
    "        continue\n",
    "    name = header['Topic'][0]    \n",
    "    datestring = header['Start Time'][0][:10]\n",
    "    if name+datestring in processed_set:\n",
    "        print(f\"Duplicated meeting: {name+datestring} ({fname}) already saved as {processed_dict[name+datestring]}\")\n",
    "        continue  # This meeting\n",
    "    processed_set.add(name+datestring)\n",
    "    processed_dict[name+datestring] = fname\n",
    "    \n",
    "    data = pd.read_csv(fullname, header=2)\n",
    "    data['Date'] = datestring\n",
    "    data['Meeting'] = name\n",
    "    data['User Email'] = data['User Email'].fillna('none') # NaNs are ignored by aggregation below\n",
    "    \n",
    "    # Join Time\tLeave Time\tDuration (Minutes)\n",
    "    if 'Join Time' in data.columns:  # Wrong output format - it is sometimes unavoidable\n",
    "        data['Total Duration (Minutes)'] = data['Duration (Minutes)']\n",
    "        data = data.drop(columns=['Join Time', 'Leave Time', 'Duration (Minutes)'])\n",
    "    \n",
    "    df = df.append(data, ignore_index=True)\n",
    "\n",
    "print('Meeting files:', len(processed_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename fields, standardize meetings that had synonyms\n",
    "\n",
    "df= df.rename({'User Email': 'email', \n",
    "               'Total Duration (Minutes)': 'minutes', \n",
    "               'Name (Original Name)': 'name',\n",
    "               'Meeting':'meeting',\n",
    "               'Date':'date'}, axis=1)\n",
    "meeting_dict = {'Biosem Zoom': 'Biosem', \n",
    "                'Biosem_spring_2021': 'Biosem',\n",
    "                'Neuroscience': 'Neuro',\n",
    "                'Computational Neuro': 'Comput'}\n",
    "df['meeting'] = df['meeting'].replace(meeting_dict)\n",
    "df.name = df.name.str.title()  # Capitalize names (for consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inexplicably, some total participation counts are stored as strings, not numbers. Correct that.\n",
    "\n",
    "df.loc[df.minutes=='Yes'] = 0 # No idea what it means, but Zoom outputed it!\n",
    "df.minutes = df.minutes.astype(int)\n",
    "df = df[df.minutes>0]  # Remove weird empty entries\n",
    "\n",
    "# Full attendance and late classes:\n",
    "df['check'] = 0.3*(df.minutes>30) + (1-0.3)*(df.minutes>50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What meetings are even there?\n",
    "set(df.meeting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participation length histogram\n",
    "if False:\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.subplot(121)\n",
    "    plt.hist(df.loc[df.meeting=='Biosem'].minutes.values, bins=50);\n",
    "    plt.title('Biosem');\n",
    "    plt.subplot(122)\n",
    "    plt.hist(df.loc[df.meeting=='Neuro'].minutes.values, bins=50);\n",
    "    plt.title('Neuro');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only analyze one type of meetings starting from here\n",
    "df = df[df.meeting==target_meeting]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the actual list of students. Note that the file name needs to match the meeting name.\n",
    "\n",
    "people = pd.read_csv(folder_name + target_meeting + '.csv', header=0, sep=',')\n",
    "people.columns = [' '.join(s.split()) for s in people.columns] # Remove repeating spaces, just in case\n",
    "# print(people.columns)\n",
    "people['name'] = people['FIRST NAME'] + ' ' + people['LAST NAME']\n",
    "people = (people\n",
    "          .drop_duplicates() # A left-over from the \"All meetings at once\" pipeline, but let's keep for a while\n",
    "          .reset_index()\n",
    "          .rename({'ID#':'id', 'Email': 'email'}, axis=1)\n",
    "          .loc[:,['id', 'email', 'name']]\n",
    "         )\n",
    "print(people.columns)\n",
    "# people.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Troubleshooting: A full list of meetings with their attendance.\n",
    "# Check if the plot makes sense.\n",
    "\n",
    "dfm = df.groupby(['date','meeting','name']).agg({'minutes': sum})\n",
    "dfm.minutes = 1*(dfm.minutes>10)\n",
    "dfm = dfm.groupby(['date', 'meeting']).agg({'minutes': sum}).reset_index()\n",
    "dfm = dfm.rename({'minutes':'people'}, axis=1)\n",
    "dfm.date = pd.to_datetime(dfm.date)\n",
    "print(\"Meetings so far:\", dfm.shape[0])\n",
    "\n",
    "plt.figure(figsize=(9,2))\n",
    "plt.plot(dfm.date.dt.dayofyear, dfm.people, '.');\n",
    "plt.xlabel('Meeting');\n",
    "plt.ylabel('People');\n",
    "\n",
    "# print(dfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any entries without email at all\n",
    "df[[len(a)<10 for a in df.email]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and process known alts\n",
    "\n",
    "df_alts = pd.read_csv(folder_name + 'alts.csv', header=0, sep=',')\n",
    "\n",
    "# First find official emails where available, and drop some users manually (e.g. the instructor)\n",
    "df_fixed = (df\n",
    "            .merge(df_alts, on='email', how='left', suffixes=['', '_r'])\n",
    "            .drop(columns=['name_r'])\n",
    "            .query(\"real_email != 'none'\")\n",
    "           )\n",
    "\n",
    "# Substitute 'wrong' emails with 'official' emails where available\n",
    "ind = (df_fixed.real_email.notna())\n",
    "df_fixed.loc[ind, 'email'] = df_fixed.loc[ind, 'real_email']\n",
    "df_fixed = df_fixed.drop(columns='real_email')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find people with emails that aren't on the official list\n",
    "# Output them, to manually create a list of alt-emails (that will be )\n",
    "\n",
    "df_lost = (df_fixed           \n",
    "           .groupby(['name','email'])\n",
    "           .agg({'minutes': sum})\n",
    "           .reset_index()\n",
    "           .merge(people, on='email', how='left', suffixes=['', '_r']) # Ignore official name (_r)\n",
    "           .drop(columns='name_r')           \n",
    "           .query('id.isna()', engine='python') # Only keep unrecognized users\n",
    "          )\n",
    "print('Unrecognized emails (uncomment to see the list):', len(df_lost.id))\n",
    "\n",
    "# Output nice human-readable form:\n",
    "# df_lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real name searher:\n",
    "token='Stef'\n",
    "df_fixed.query('name.notna()', engine='python').query('name.str.match(@token)', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lookup correct names, and drop all users who are not on bip\n",
    "df_fixed = (df_fixed\n",
    "            .merge(people, on='email', how='left', suffixes=['_l', '']) # This time keep official names only\n",
    "            .drop(columns=['name_l', 'id', 'Guest'])\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a summary\n",
    "\n",
    "dfs = (df_fixed\n",
    "       .groupby(['name','email'])\n",
    "       .agg({'check': sum})\n",
    "       .reset_index()\n",
    "      )\n",
    "\n",
    "# dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Piazza grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all students enrolled on Piazza, with their Piazza names\n",
    "# Here make sure the list has only 1 email, and this email is correct. Some people like to include\n",
    "# more than one email for some reason...\n",
    "\n",
    "people_piazza = pd.DataFrame(columns=['name', 'email'])\n",
    "lines = open(folder_name + 'Piazza.list', 'r', encoding='utf-8').readlines()\n",
    "for line in lines:\n",
    "    l = line.strip().split(' ')\n",
    "    email = l[-1]\n",
    "    name = ' '.join(l[:-1])\n",
    "    if name != '': # Ignore unregistered users\n",
    "        people_piazza = people_piazza.append({'name': name, 'email': email}, ignore_index=True)\n",
    "        \n",
    "# people_piazza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all piazza pages. All of them should be saved as txt files.\n",
    "# NOTE: There's no safety check on the content of TXT files, so no other TXT files are allowed in this folder!\n",
    "# In each page, identify responses, and count special marks.\n",
    "\n",
    "df_piazza = pd.DataFrame(columns=['name', 'work', 'grade', 'message'])\n",
    "cool = 'ðŸ”¥ðŸ’¡ðŸ’Ž'\n",
    "rejected = 'ðŸ›‘'\n",
    "splitter = 'Resolved Unresolved'\n",
    "\n",
    "file_list = os.listdir(folder_name)\n",
    "for fname in file_list:\n",
    "    if fname[-3:]!='txt':\n",
    "        continue # Ignore everything that is not a zoom log    \n",
    "    s = open(folder_name + fname, 'r', encoding='utf-8').read()\n",
    "    title = s[:s.find('\\n')]\n",
    "    print(fname, ':', title)\n",
    "    \n",
    "    messages = s.split(splitter)[1:]  # Skip the homework itself (number 0)\n",
    "    for message in messages:\n",
    "        first = max(0, message.find('days ago')+9)\n",
    "        last  = message.find('\\nhelpful! ')        \n",
    "        \n",
    "        grade = ''\n",
    "        for emoji in cool:\n",
    "            if emoji in message:\n",
    "                grade = 'good'\n",
    "        for emoji in rejected:\n",
    "            if emoji in message:\n",
    "                grade = 'bad'\n",
    "        for name in people_piazza.name:        \n",
    "            if name in message:\n",
    "                df_piazza = df_piazza.append({'name': name, 'work':title, 'grade':grade,\n",
    "                                              'message':message[first:last]}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now summarize, then merge left on the full list of people\n",
    "\n",
    "df_piazza['good'] = df_piazza.grade.str.match('good')\n",
    "df_piazza['bad']  = df_piazza.grade.str.match('bad')\n",
    "\n",
    "dfsp = (df_piazza        \n",
    "        .groupby(['name'])\n",
    "        .agg({'work':'count', 'good':'sum', 'bad':'sum'})\n",
    "        .reset_index()\n",
    "        .rename({'work':'total'}, axis=1)\n",
    "       )\n",
    "dfsp = (people_piazza\n",
    "        .merge(dfsp, on='name', how='left')\n",
    "       )\n",
    "\n",
    "dfsp.loc[dfsp.total.isna(), ['total', 'good', 'bad']] = 0\n",
    "dfsp.total = dfsp.total.astype(int)\n",
    "dfsp.good  = dfsp.good.astype(int)\n",
    "dfsp.bad   = dfsp.bad.astype(int)\n",
    "\n",
    "# dfsp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zoom chats\n",
    "\n",
    "(We assume that they were pre-computed by the `zoom_chat_analyzer` notebook.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chats = pd.read_csv(folder_name + 'zoom_chats.csv')\n",
    "total_meetings = df_chats.number.max()\n",
    "df_chats = df_chats.query(\"name != 'Arseny Khakhalin'\")\n",
    "\n",
    "def find_percentile(x, data):\n",
    "    return sum(np.array(data)>=x)/len(data)\n",
    "\n",
    "df_chats['percentile'] = [find_percentile(x, df_chats.number.values) for x in df_chats.number]\n",
    "df_chats.percentile = np.round(df_chats.percentile*100).astype(int)\n",
    "df_chats.columns = ['name_zoom', 'n_chats', 'percentile_chats']\n",
    "# df_chats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final summary grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Full output\n",
    "\n",
    "df_full = (dfsp\n",
    "           .merge(dfs, on='email', suffixes=['_piazza','_zoom'])\n",
    "           .merge(df_chats, on='name_zoom', how='left')           \n",
    "          )\n",
    "df_full.n_chats = df_full.n_chats.fillna(0).astype(int)\n",
    "df_full.percentile_chats = df_full.percentile_chats.fillna(100).astype(int)\n",
    "\n",
    "# Show the full giant thing:\n",
    "with pd.option_context('display.max_rows', 14000, 'display.width', 1000):\n",
    "    # print(df_full)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many missed assignments are problematic?\n",
    "# For Neuro this semester we seem to have 34 classes and 21 homework\n",
    "\n",
    "print('Can miss classes, and still pass:', 0.2*34)\n",
    "print('Can miss classes, and still get a B:', 0.1*34)\n",
    "print('Can miss homeworks, and still pass:', 0.2*21)\n",
    "print('Can miss homeworks, and still get a B:', 0.1*21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "classes_so_far = 23\n",
    "works_so_far = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grades\n",
    "#                 0    1     2    3     4     5    6\n",
    "grade_letters = ['F', 'C', 'B-', 'B', 'B+', 'A-', 'A']\n",
    "\n",
    "df_full['grade'] = 3\n",
    "df_full.grade = df_full.grade.where(~(df_full.check < np.round(classes_so_far*0.9)), 1)\n",
    "df_full.grade = df_full.grade.where(~(df_full.check < np.round(classes_so_far*0.8)), 0)\n",
    "df_full.grade = df_full.grade.where(~(df_full.total < np.round(works_so_far*0.9)), 1)\n",
    "df_full.grade = df_full.grade.where(~(df_full.total < np.round(works_so_far*0.8)), 0)\n",
    "df_full.loc[(df_full.good >= 3) & (df_full.grade >= 1), 'grade'] += 1\n",
    "df_full.loc[(df_full.good >= 6) & (df_full.grade >= 1), 'grade'] += 1\n",
    "df_full.loc[(df_full.percentile_chats <= 20) & (df_full.grade >= 1), 'grade'] += 1\n",
    "df_full.grade = np.minimum(5, df_full.grade)\n",
    "# Translate to letters:\n",
    "df_full.grade = [grade_letters[i] for i in df_full.grade]\n",
    "\n",
    "df_full.head(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze one student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check individual records of needed\n",
    "token = 'Megi'\n",
    "\n",
    "# Full attendance:\n",
    "all_meetings = df.groupby('date').agg({'name':'count'}).reset_index()\n",
    "partial = df.loc[df.name.str.contains(token)]\n",
    "out = all_meetings[['date']].merge(partial, on='date', how='left')[['date','name','email','minutes','check']]\n",
    "out.loc[out.check.isna(),'check'] = 0\n",
    "print(sum(out.check))\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All homeworks:\n",
    "df_piazza[df_piazza.name.str.contains(token)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mid-term letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(df_full, df_piazza, i):\n",
    "    # Write a full response for one student\n",
    "    \n",
    "    sec = df_full.iloc[i]\n",
    "    name = sec.name_piazza\n",
    "    \n",
    "    flag_submitted_something = False\n",
    "    if name in df_piazza.name.unique():\n",
    "        flag_submitted_something = True\n",
    "        missing_work = (df_piazza\n",
    "                        .groupby(['work', 'name'])\n",
    "                        .agg({'message':'count'})\n",
    "                        .reset_index()\n",
    "                        .pivot_table(index='work', columns='name', values='message')\n",
    "                        .reset_index()\n",
    "                        [['work', name]]\n",
    "                        .set_axis(['work', 'name'], axis=1, inplace=False)\n",
    "                        .query('name.isna()', engine='python')\n",
    "                        .work\n",
    "                        .sort_values()\n",
    "                        .tolist()\n",
    "                     )\n",
    "    \n",
    "    def remove_double_spaces(s):\n",
    "        s = s.replace('\\n', ' ')\n",
    "        return ' '.join([c for c in s.split(' ') if c])\n",
    "    \n",
    "    print(f\"{sec.name_zoom} {sec.email}:\")\n",
    "    print(f\"Dear {sec.name_piazza.split()[0]},\")\n",
    "    print(f\"based on my records as of {max(df.date)}\")\n",
    "    print(f\"you have attended {np.round(sec.check).astype(int)} classes \", end='')\n",
    "    print(f\"(out of {classes_so_far} that we had so far), \")\n",
    "    print(f\"and submitted {sec.total} homeworks (out of {works_so_far} that we had)\")   \n",
    "    if sec.good>0:\n",
    "        print(f\"{sec.good} of these homeworks were really good!! (and others were also fine :)\")\n",
    "    if sec.total < works_so_far and flag_submitted_something:\n",
    "        print(f\"\\n(Works that are missing: {'; '.join(missing_work)})\\n\")\n",
    "    print(f\"You were active in {sec.n_chats} class sessions\", end='')\n",
    "    if sec.percentile_chats<50:\n",
    "        print(f\", which places you in the top {sec.percentile_chats}%\", end='')\n",
    "    else:\n",
    "        print(f\", which places you in the bottom {100-sec.percentile_chats}%\", end='')\n",
    "    print(\" in terms of class participation.\")\n",
    "    \n",
    "    print(f\"Taking all of it into account, your current automatically projected grade is \", end='')\n",
    "    if sec.grade=='B': print('between B and B+')\n",
    "    elif sec.grade=='B+': print('between B+ and A-')        \n",
    "    else: print(sec.grade)\n",
    "    \n",
    "    if sec.grade in {'F', 'C'}:\n",
    "        message = \"\"\"If you want to improve, you can submit missing homeworks. \n",
    "              For missed lab work, just do the lab, and submit your work, as described in the assignment. \n",
    "              For missed questions, at this point the assignment is a bit different.\n",
    "              You will need to answer the following question: \n",
    "              'What is the most interesting thing that you learned that week,Â and what makes it interesting for you?'. \n",
    "              I would expect about a paragraph of text, with explicit references to what you learned from \n",
    "              home assignments, and from our class discussions. AdditionalÂ sources are also welcome!\"\"\"\n",
    "        print('\\n'+remove_double_spaces(message))\n",
    "    print(\"\\n(If anything about this summary does not ring right to you, please email me, \" \\\n",
    "          \"and I'll double-check my records!)\")\n",
    "        \n",
    "response(df_full, df_piazza, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.where(df_full.name_piazza.str.match('Ste'))[0][0]\n",
    "print(i)\n",
    "response(df_full, df_piazza, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(df_full.shape[0]):\n",
    "    response(df_full, df_piazza, i)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ouput the summary csv\n",
    "#recognized.to_csv(folder_name + '../attendance_summary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
