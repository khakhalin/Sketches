{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zoom grader\n",
    "\n",
    "Loads zoom reports from a pre-defined folder, and calculates attendance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_names = 0\n",
    "# Set this global var to 1 before pushing to git (preserves anonymity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = '../../data/attendance/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all attendance data\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "file_list = os.listdir(folder_name)\n",
    "print(\"Total files: \",len(file_list))\n",
    "\n",
    "for fname in file_list:\n",
    "    # print(fname)\n",
    "    if fname[-3:]!='csv':\n",
    "        continue # Ignore everything that is not a zoom log\n",
    "    fullname = folder_name + fname\n",
    "    header = pd.read_csv(fullname, header=0, nrows=1)\n",
    "    name = header['Topic'][0]\n",
    "    datestring = header['Start Time'][0][:10]\n",
    "    # print(fname, header['Start Time'].values)    \n",
    "    \n",
    "    data = pd.read_csv(fullname, header=2)\n",
    "    data['Date'] = datestring\n",
    "    data['Meeting'] = name\n",
    "    data['User Email'] = data['User Email'].fillna('none') # NaNs are ignored by aggregation below\n",
    "    \n",
    "    df = df.append(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.rename({'User Email': 'email', \n",
    "               'Total Duration (Minutes)': 'minutes', \n",
    "               'Name (Original Name)': 'name',\n",
    "               'Meeting':'meeting',\n",
    "               'Date':'date'}, axis=1)\n",
    "meeting_dict = {'Neuro Lab - Sep 10': 'Neuro', \n",
    "                \"Arseny Khakhalin's Zoom Meeting\": 'Neuro', \n",
    "                \"Intro Neuro\": 'Neuro',\n",
    "                'Biosem 00': 'Biosem', 'Bard Biosem': 'Biosem'}\n",
    "df['meeting'] = df['meeting'].replace(meeting_dict)\n",
    "df.name = df.name.str.title() # Capitalize (for consistency)\n",
    "df['check'] = 1*(df.minutes>30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the list of students\n",
    "people = pd.read_csv(folder_name + 'people.txt', header=0, sep='\\t')\n",
    "people['name'] = people['first'] + ' ' + people['last']\n",
    "people = people.drop_duplicates()\n",
    "people.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of meetings\n",
    "\n",
    "dfm = df.groupby(['date','meeting','name']).agg({'minutes': sum})\n",
    "dfm.minutes = 1*(dfm.minutes>10)\n",
    "dfm = dfm.groupby(['date', 'meeting']).agg({'minutes': sum}).reset_index()\n",
    "dfm = dfm.rename({'minutes':'people'}, axis=1)\n",
    "dfm.date = pd.to_datetime(dfm.date)\n",
    "\n",
    "plt.figure(figsize=(9,2))\n",
    "plt.plot(dfm.date.dt.dayofyear, dfm.people, '.');\n",
    "plt.xlabel('Meeting');\n",
    "plt.ylabel('People');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at attendance of selected students\n",
    "# df.loc[df.name.str[:3]=='Ser'].sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALl possible dates\n",
    "# sorted(df.date.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at all participants on a selected date\n",
    "# df.loc[df.date=='10/26/2020'].sort_values(by='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteratively build summaries\n",
    "\n",
    "dfs = df.groupby(['date', 'meeting', 'name']).agg({'minutes' : sum})\n",
    "dfs = dfs.reset_index()                                 # Get rid of hierarchical indices\n",
    "dfs['check'] = 1*(dfs.minutes>30)                       # Participation threshold\n",
    "\n",
    "dfs = dfs.groupby(['name','meeting']).agg({'check': sum})\n",
    "dfs = dfs.reset_index()\n",
    "dfs.name = dfs.name.str.strip()                         # Remove leading and ending spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 1400, 'display.width', 1000):\n",
    "    if not hide_names:\n",
    "        #print(dfs)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a manually created list of synonims to unify spelling\n",
    "# Then look for official emails\n",
    "\n",
    "alts = pd.read_csv(folder_name + 'alt-people.txt', header=0, sep=',')\n",
    "excluded = pd.read_csv(folder_name + 'exclude.txt', header=0, sep=',')\n",
    "\n",
    "recognized = dfs.copy().merge(alts, on='name', how='left')\n",
    "#recognized.name = recognized.name.str.replace('\\t',' ')\n",
    "\n",
    "ind = recognized.translation.notnull()\n",
    "recognized.loc[ind, 'name'] = recognized.loc[ind,'translation']\n",
    "\n",
    "recognized = (recognized\n",
    "              .drop(columns='translation')                            \n",
    "              .groupby(['name','meeting']).agg({'check': sum}).reset_index()\n",
    "              .merge(people, on='name', how='left', suffixes=['', '_r'])\n",
    "              .drop(columns=['first', 'last'])\n",
    "              )\n",
    "\n",
    "lost = recognized[recognized.email.isnull()]\n",
    "lost = (lost.merge(excluded, on='name', how='left', indicator=True).\n",
    "        query('_merge==\"left_only\"').\n",
    "        drop(columns=['_merge','email']))\n",
    "\n",
    "with pd.option_context('display.max_rows', 1400, 'display.width', 1000):\n",
    "    if not hide_names:        \n",
    "        print(lost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join(lost.name.values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a manually created list of synonims to unify spelling\n",
    "\n",
    "lost = dfs.querya\n",
    "\n",
    "attempt = lost.merge(alts, on='name', how='inner') # Adds column 'translation'\n",
    "attempt3 = attempt3[attempt3.translation.notnull()]\n",
    "attempt3 = attempt3.merge(people[['name','email']], left_on='translation', right_on='name', suffixes=[None, '_y'])\n",
    "attempt3 = attempt3[['name', 'email']].drop_duplicates()\n",
    "lost = lost.merge(attempt3['name'], on='name', how='outer', indicator=True).query('_merge==\"left_only\"')\n",
    "lost = lost.drop(columns='_merge')\n",
    "\n",
    "# Any records still unidentified?\n",
    "lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify those who don't have emails set, but have a reasonable name\n",
    "\n",
    "lost = dfs.query('email==\"none\"').copy()\n",
    "lost['name2'] = lost.name.map(lambda s: ' '.join(s.split(' ')[:2])) # Only leave 2 first words\n",
    "lost.name2 = lost.name2.str.title()                                 # Capitalize every word\n",
    "lost.name = lost.name.str.title()           # Capitalize first letter of every word\n",
    "lost = lost[['name', 'name2', 'check']]\n",
    "\n",
    "# Archetypical filtering operations here (3 times in a row):\n",
    "# 1. Lookup emails\n",
    "# 2. Remove those that were found. To avoid massive renaming and dropping columns,\n",
    "# only look up one column (the name itself).\n",
    "\n",
    "attempt1 = lost.merge(people[['name', 'email']], on='name', how='inner') # Those with correct name\n",
    "lost = lost.merge(attempt1['name'], on='name', how='outer', indicator=True, suffixes=[None, '_y']).query('_merge==\"left_only\"')\n",
    "lost = lost.drop(columns='_merge')\n",
    "attempt1 = attempt1[['name', 'email']].drop_duplicates()\n",
    "\n",
    "# Those with almost correct name (try to interpret first 2 words as a name)\n",
    "attempt2 = lost.merge(people[['name', 'email']], left_on='name2', right_on='name', how='inner')\n",
    "# Cannot clean it up yet, still need name2 to project back\n",
    "lost = lost.merge(attempt2['name2'], on='name2', how='outer', indicator=True).query('_merge==\"left_only\"')\n",
    "lost = lost[['name', 'check']]\n",
    "attempt2 = attempt2.rename({'name_x': 'name'}, axis=1)[['name', 'email']].drop_duplicates()\n",
    "\n",
    "# Now refer to a manual translation table\n",
    "alts = pd.read_csv(folder_name + 'alt-people.txt', header=0, sep=',')\n",
    "\n",
    "attempt3 = lost.merge(alts, on='name', how='inner') # Adds column 'translation'\n",
    "attempt3 = attempt3[attempt3.translation.notnull()]\n",
    "attempt3 = attempt3.merge(people[['name','email']], left_on='translation', right_on='name', suffixes=[None, '_y'])\n",
    "attempt3 = attempt3[['name', 'email']].drop_duplicates()\n",
    "lost = lost.merge(attempt3['name'], on='name', how='outer', indicator=True).query('_merge==\"left_only\"')\n",
    "lost = lost.drop(columns='_merge')\n",
    "\n",
    "# Any records still unidentified?\n",
    "lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# people.name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meetings unidentified people attended\n",
    "# print(df[['name','date','minutes','meeting']].merge(lost['name'], on='name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to fix emails in the original dataset\n",
    "\n",
    "df2 = df.copy()\n",
    "df2.name = df2.name.str.title()             # Standardize capitalization (or aliases table won't work)\n",
    "df2.loc[df2.email=='none', 'email'] = None\n",
    "for df_right in [attempt1, attempt2, attempt3]:    \n",
    "    df2 = df2.merge(df_right, on='name', how='left', suffixes=[None, '_new'])    \n",
    "    df2.loc[df2.email.isnull(), 'email'] = df2.loc[df2.email.isnull(), 'email_new']\n",
    "    df2 = df2.drop(columns='email_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.loc[df2.name.str[:3]=='Win'].sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize\n",
    "df2 = df2.groupby(['meeting','email']).agg({'check': sum}).reset_index()\n",
    "df2 = df2.merge(people[['email', 'name']], on='email').reset_index()\n",
    "\n",
    "df2 = df2[['meeting', 'name', 'email', 'check']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obfuscate(ser):\n",
    "    out = ser.copy()\n",
    "    for i in range(len(out)):\n",
    "        out[i] = 'x'*len(out[i])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 14000, 'display.width', 1000):\n",
    "    df2temp = df2.copy()\n",
    "    if hide_names:\n",
    "        df2temp.name = obfuscate(df2temp.name)\n",
    "        df2temp.email = obfuscate(df2temp.email)\n",
    "    print(df2temp)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\n'.join(df2.loc[df2.meeting==\"Neuro\"].sort_values(by='name').name.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df2.loc[df2.meeting=='Neuro'].sort_values(by='name').drop(columns=['meeting', 'email'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
