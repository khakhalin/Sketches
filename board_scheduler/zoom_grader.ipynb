{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zoom grader\n",
    "\n",
    "Loads zoom reports from a pre-defined folder, and calculates attendance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hide_names = 0\n",
    "# Set this global var to 1 before pushing to git (preserves anonymity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = '../../data/attendance/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all attendance data\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "file_list = os.listdir(folder_name)\n",
    "print(\"Total files: \",len(file_list))\n",
    "\n",
    "for fname in file_list:\n",
    "    # print(fname)\n",
    "    if fname[-3:]!='csv':\n",
    "        continue # Ignore everything that is not a zoom log\n",
    "    fullname = folder_name + fname\n",
    "    header = pd.read_csv(fullname, header=0, nrows=1)\n",
    "    name = header['Topic'][0]\n",
    "    datestring = header['Start Time'][0][:10]\n",
    "    # print(fname, header['Start Time'].values)    \n",
    "    \n",
    "    data = pd.read_csv(fullname, header=2)\n",
    "    data['Date'] = datestring\n",
    "    data['Meeting'] = name\n",
    "    data['User Email'] = data['User Email'].fillna('none') # NaNs are ignored by aggregation below\n",
    "    \n",
    "    df = df.append(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.rename({'User Email': 'email', \n",
    "               'Total Duration (Minutes)': 'minutes', \n",
    "               'Name (Original Name)': 'name',\n",
    "               'Meeting':'meeting',\n",
    "               'Date':'date'}, axis=1)\n",
    "meeting_dict = {'Neuro Lab - Sep 10': 'Neuro', \n",
    "                \"Arseny Khakhalin's Zoom Meeting\": 'Neuro', \n",
    "                \"Intro Neuro\": 'Neuro',\n",
    "                'Biosem 00': 'Biosem', 'Bard Biosem': 'Biosem'}\n",
    "df['meeting'] = df['meeting'].replace(meeting_dict)\n",
    "df.name = df.name.str.title() # Capitalize (for consistency)\n",
    "df['check'] = 1*(df.minutes>30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check individual records of needed\n",
    "#df.loc[df.name.str[:3]=='Han']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the list of students\n",
    "people = pd.read_csv(folder_name + 'people.txt', header=0, sep='\\t')\n",
    "people['name'] = people['first'] + ' ' + people['last']\n",
    "people = people.drop_duplicates()\n",
    "people = people.reset_index()\n",
    "people.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALl names\n",
    "#for i in range(people.shape[0]):\n",
    "#    print(f\"{people.loc[i, 'first']} {people.loc[i,'last']}\", end=' | ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of meetings\n",
    "dfm = df.groupby(['date','meeting','name']).agg({'minutes': sum})\n",
    "dfm.minutes = 1*(dfm.minutes>10)\n",
    "dfm = dfm.groupby(['date', 'meeting']).agg({'minutes': sum}).reset_index()\n",
    "dfm = dfm.rename({'minutes':'people'}, axis=1)\n",
    "dfm.date = pd.to_datetime(dfm.date)\n",
    "\n",
    "plt.figure(figsize=(9,2))\n",
    "plt.plot(dfm.date.dt.dayofyear, dfm.people, '.');\n",
    "plt.xlabel('Meeting');\n",
    "plt.ylabel('People');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at attendance of selected students\n",
    "key = 'Dan'\n",
    "res = df.loc[df.name.str[:len(key)]==key].sort_values(by='date')\n",
    "print(res.shape[0], 'rows')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALl possible dates\n",
    "# sorted(df.date.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at all participants on a selected date\n",
    "# df.loc[df.date=='10/26/2020'].sort_values(by='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteratively build summaries\n",
    "\n",
    "dfs = df.groupby(['date', 'meeting', 'name', 'email']).agg({'minutes' : sum})\n",
    "dfs = dfs.reset_index()                                 # Get rid of hierarchical indices\n",
    "dfs['check'] = 1*(dfs.minutes>30)                       # Participation threshold\n",
    "\n",
    "dfs = dfs.groupby(['name', 'meeting', 'email']).agg({'check': sum}).reset_index()\n",
    "dfs.name = dfs.name.str.strip()                         # Remove leading and ending spaces\n",
    "\n",
    "# Normalize names based on the official record where email is available\n",
    "dfs = dfs.merge(people, on='email', how='left', suffixes=['','_r'])\n",
    "ind = (dfs.email != 'none') & (dfs.name_r.notna())\n",
    "dfs.loc[ind,'name'] = dfs.loc[ind,'name_r']\n",
    "dfs = dfs.drop(columns=['name_r','index','first','last'])\n",
    "# print(dfs.loc[dfs.name.str[:3]=='Dan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 1400, 'display.width', 1000):\n",
    "    if not hide_names:\n",
    "        # print(dfs)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a manually created list of synonims to unify spelling\n",
    "# Then look for official emails\n",
    "\n",
    "alts = pd.read_csv(folder_name + 'alt-people.txt', header=0, sep=',') # A dict of alt-names\n",
    "excluded = pd.read_csv(folder_name + 'exclude.txt', header=0, sep=',')\n",
    "\n",
    "recognized = dfs.copy().merge(alts, on='name', how='left')\n",
    "\n",
    "# Replace alt-names with real names, where alt-names were found\n",
    "ind = recognized.translation.notnull()\n",
    "recognized.loc[ind, 'name'] = recognized.loc[ind,'translation']\n",
    "\n",
    "# Combine different copies of the same person, then re-link emails\n",
    "recognized = (recognized\n",
    "              .drop(columns='translation')                            \n",
    "              .groupby(['name','meeting']).agg({'check': sum}).reset_index()\n",
    "              .merge(people, on='name', how='left', suffixes=['', '_r'])\n",
    "              .drop(columns=['first', 'last', 'index'])\n",
    "              )\n",
    "\n",
    "# Sanity checks row\n",
    "# print(alts.loc[alts.name.str[:3]=='Equ'])\n",
    "\n",
    "lost = recognized[recognized.email.isnull()]\n",
    "lost = (lost.merge(excluded, on='name', how='left', indicator=True).\n",
    "        query('_merge==\"left_only\"').\n",
    "        drop(columns=['_merge','email']))\n",
    "\n",
    "with pd.option_context('display.max_rows', 1400, 'display.width', 1000):\n",
    "    if not hide_names:        \n",
    "        print(lost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 14000, 'display.width', 1000):\n",
    "    print(recognized.sort_values('meeting'))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ouput the summary csv\n",
    "recognized.to_csv(folder_name + '../attendance_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\n'.join(df2.loc[df2.meeting==\"Neuro\"].sort_values(by='name').name.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df2.loc[df2.meeting=='Neuro'].sort_values(by='name').drop(columns=['meeting', 'email'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
