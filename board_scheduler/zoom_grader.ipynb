{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zoom grader\n",
    "\n",
    "Loads zoom reports from a pre-defined folder, and calculates attendance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recently identified complicatoins\n",
    "\n",
    "Unlike in Neuro class, some people in biosem didn't put their emails on zoom, or only did it late."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan:\n",
    "\n",
    "1. Load data from BIP\n",
    "1. Process Zoom logs, ignore repetitions, summarize\n",
    "1. Filter only one class\n",
    "1. Read the actual list of students (separate for every class)\n",
    "1. Use a substitutition table \"name --> email\" (separate file, one for all classes) to either substitute entries, or disable entries (special \"command\" for making it ignore an entry)\n",
    "1. Using email as id, connect two databases. Output summary, as well as a list of failed entries (present on Zoom, but absent on BIP).\n",
    "\n",
    "Piazza grader:\n",
    "\n",
    "1. Load a list of Piazza people\n",
    "2. Go through saved Piazza contributions, tabulate participation\n",
    "3. Read attendance summary from part 1 (above)\n",
    "4. Output a full table (screen & csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = '../../data/attendance/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read attendance data\n",
    "\n",
    "df = pd.DataFrame()\n",
    "file_list = os.listdir(folder_name)\n",
    "print(\"Total files: \",len(file_list))\n",
    "\n",
    "processed_set = set()\n",
    "processed_dict = {}\n",
    "for fname in file_list:\n",
    "    if fname[-3:]!='csv':\n",
    "        continue # Ignore everything that is not a csv\n",
    "    fullname = folder_name + fname\n",
    "    header = pd.read_csv(fullname, header=0, nrows=1) # Attempt to read the header\n",
    "    if 'Topic' not in header.columns: # Not a zoom log, skip this one\n",
    "        continue\n",
    "    name = header['Topic'][0]    \n",
    "    datestring = header['Start Time'][0][:10]\n",
    "    if name+datestring in processed_set:\n",
    "        print(f\"Duplicated meeting: {name+datestring} ({fname}) already saved as {processed_dict[name+datestring]}\")\n",
    "        continue  # This meeting\n",
    "    processed_set.add(name+datestring)\n",
    "    processed_dict[name+datestring] = fname\n",
    "    \n",
    "    data = pd.read_csv(fullname, header=2)\n",
    "    data['Date'] = datestring\n",
    "    data['Meeting'] = name\n",
    "    data['User Email'] = data['User Email'].fillna('none') # NaNs are ignored by aggregation below\n",
    "    \n",
    "    df = df.append(data, ignore_index=True)\n",
    "\n",
    "print('Meeting files:', len(processed_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename fields, standardize meetings that had synonyms\n",
    "\n",
    "df= df.rename({'User Email': 'email', \n",
    "               'Total Duration (Minutes)': 'minutes', \n",
    "               'Name (Original Name)': 'name',\n",
    "               'Meeting':'meeting',\n",
    "               'Date':'date'}, axis=1)\n",
    "meeting_dict = {'Biosem Zoom': 'Biosem', \n",
    "                'Biosem_spring_2021': 'Biosem',\n",
    "                'Neuroscience': 'Neuro',\n",
    "                'Computational Neuro': 'Comput'}\n",
    "df['meeting'] = df['meeting'].replace(meeting_dict)\n",
    "df.name = df.name.str.title()  # Capitalize names (for consistency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inexplicably, some total participation counts are stored as strings, not numbers\n",
    "# So correct that.\n",
    "\n",
    "df.loc[df.minutes=='Yes'] = 0 # No idea what it means, but Zoom outputed it!!!\n",
    "ind = [type(a)!=int for a in df.minutes.values]\n",
    "df.loc[ind, 'minutes'] = [int(a) for a in df.loc[ind].minutes.values]\n",
    "df = df[df.minutes>0]  # Remove weird empty entries\n",
    "\n",
    "# df['check'] = 1*(df.minutes>40) # Simple attendance\n",
    "df['check'] = 0.3*(df.minutes>30) + 0.7*(df.minutes>50) # Full attendance and late classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What meetings are even there?\n",
    "set(df.meeting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participation length histogram\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.subplot(121)\n",
    "plt.hist(df.loc[df.meeting=='Biosem'].minutes.values, bins=50);\n",
    "plt.title('Biosem');\n",
    "plt.subplot(122)\n",
    "plt.hist(df.loc[df.meeting=='Neuro'].minutes.values, bins=50);\n",
    "plt.title('Neuro');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only analyze one type of meetings starting from here\n",
    "\n",
    "target_meeting = 'Neuro' # Options: {'Biosem', 'Comput', 'Neuro'}\n",
    "df = df[df.meeting==target_meeting]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check individual records of needed\n",
    "token = 'Ell'\n",
    "all_meetings = df.groupby('date').agg({'name':'count'}).reset_index()\n",
    "partial = df.loc[df.name.str.match(token)]\n",
    "out = all_meetings[['date']].merge(partial, on='date', how='left')[['date','name','email','minutes','check']]\n",
    "out.loc[out.check.isna(),'check'] = 0\n",
    "print(sum(out.check))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the actual list of students. Note that the file name needs to match the meeting name.\n",
    "\n",
    "people = pd.read_csv(folder_name + target_meeting + '.csv', header=0, sep=',')\n",
    "people.columns = [' '.join(s.split()) for s in people.columns] # Remove repeating spaces, just in case\n",
    "# print(people.columns)\n",
    "people['name'] = people['FIRST NAME'] + ' ' + people['LAST NAME']\n",
    "people = (people\n",
    "          .drop_duplicates() # A left-over from the \"All meetings at once\" pipeline, but let's keep for a while\n",
    "          .reset_index()\n",
    "          .rename({'ID#':'id', 'Email': 'email'}, axis=1)\n",
    "          .loc[:,['id', 'email', 'name']]\n",
    "         )\n",
    "print(people.columns)\n",
    "# people.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Troubleshooting: A full list of meetings with their attendance.\n",
    "# Check if the plot makes sense.\n",
    "\n",
    "dfm = df.groupby(['date','meeting','name']).agg({'minutes': sum})\n",
    "dfm.minutes = 1*(dfm.minutes>10)\n",
    "dfm = dfm.groupby(['date', 'meeting']).agg({'minutes': sum}).reset_index()\n",
    "dfm = dfm.rename({'minutes':'people'}, axis=1)\n",
    "dfm.date = pd.to_datetime(dfm.date)\n",
    "print(\"Meetings so far:\", dfm.shape[0])\n",
    "\n",
    "plt.figure(figsize=(9,2))\n",
    "plt.plot(dfm.date.dt.dayofyear, dfm.people, '.');\n",
    "plt.xlabel('Meeting');\n",
    "plt.ylabel('People');\n",
    "\n",
    "# print(dfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any entries without email at all\n",
    "df[[len(a)<10 for a in df.email]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and process known alts\n",
    "\n",
    "df_alts = pd.read_csv(folder_name + 'alts.csv', header=0, sep=',')\n",
    "\n",
    "# First find official emails where available, and drop some users manually (e.g. the instructor)\n",
    "df_fixed = (df\n",
    "            .merge(df_alts, on='email', how='left', suffixes=['', '_r'])\n",
    "            .drop(columns=['name_r'])\n",
    "            .query(\"real_email != 'none'\")\n",
    "           )\n",
    "\n",
    "# Substitute 'wrong' emails with 'official' emails where available\n",
    "ind = (df_fixed.real_email.notna())\n",
    "df_fixed.loc[ind, 'email'] = df_fixed.loc[ind, 'real_email']\n",
    "df_fixed = df_fixed.drop(columns='real_email')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find people with emails that aren't on the official list\n",
    "# Output them, to manually create a list of alt-emails (that will be )\n",
    "\n",
    "df_lost = (df_fixed           \n",
    "           .groupby(['name','email'])\n",
    "           .agg({'minutes': sum})\n",
    "           .reset_index()\n",
    "           .merge(people, on='email', how='left', suffixes=['', '_r']) # Ignore official name (_r)\n",
    "           .drop(columns='name_r')           \n",
    "           .query('id.isna()', engine='python') # Only keep unrecognized users\n",
    "          )\n",
    "print('Rows found:', len(df_lost.id))\n",
    "#print('\\n'.join([a for a in df_lost['name'] + ',' + df_lost['email']])) # Output csv\n",
    "\n",
    "#df_lost # Output nice human-readable form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lookup correct names, and drop all users who are not on bip\n",
    "df_fixed = (df_fixed\n",
    "            .merge(people, on='email', how='left', suffixes=['_l', '']) # This time keep official names only\n",
    "            .drop(columns=['name_l', 'id', 'Guest'])\n",
    "#            .query('name.notna()', engine='python') # Drop people who are not on bip\n",
    "           )\n",
    "\n",
    "df_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a summary\n",
    "\n",
    "dfs = (df_fixed\n",
    "       .groupby(['name','email'])\n",
    "       .agg({'check': sum})\n",
    "       .reset_index()\n",
    "      )\n",
    "\n",
    "# dfs.sort_values(by='check')\n",
    "# dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Troubleshooter**: for a given student, find all meetings they did and did not attend.\n",
    "\n",
    "df_meetings = pd.DataFrame({'date': [a for a in set(df_fixed['date'].values)]})\n",
    "token = 'yyy'\n",
    "out = (df_meetings\n",
    "       .merge(df_fixed.loc[df_fixed.name.str[:len(token)] == token], on='date', how='left')\n",
    "       .sort_values(by='date')\n",
    "       .query('minutes.notna()', engine='python'))\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Piazza grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all students enrolled on Piazza, with their Piazza names\n",
    "# Here make sure the list has only 1 email, and this email is correct. Some people like to include\n",
    "# more than one email for some reason...\n",
    "\n",
    "people_piazza = pd.DataFrame(columns=['name', 'email'])\n",
    "lines = open(folder_name + 'Piazza.list', 'r', encoding='utf-8').readlines()\n",
    "for line in lines:\n",
    "    l = line.strip().split(' ')\n",
    "    email = l[-1]\n",
    "    name = ' '.join(l[:-1])\n",
    "    if name != '': # Ignore unregistered users\n",
    "        people_piazza = people_piazza.append({'name': name, 'email': email}, ignore_index=True)\n",
    "        \n",
    "# people_piazza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all piazza pages. All of them should be saved as txt files.\n",
    "# NOTE: There's no safety check on the content of TXT files, so no other TXT files are allowed in this folder!\n",
    "# In each page, identify responses, and count special marks.\n",
    "\n",
    "df_piazza = pd.DataFrame(columns=['name', 'work', 'grade', 'message'])\n",
    "cool = 'ðŸ”¥ðŸ’¡ðŸ’Ž'\n",
    "rejected = 'ðŸ›‘'\n",
    "splitter = 'Resolved Unresolved'\n",
    "\n",
    "file_list = os.listdir(folder_name)\n",
    "for fname in file_list:\n",
    "    if fname[-3:]!='txt':\n",
    "        continue # Ignore everything that is not a zoom log    \n",
    "    s = open(folder_name + fname, 'r', encoding='utf-8').read()\n",
    "    title = s[:s.find('\\n')]\n",
    "    print(fname, ':', title)\n",
    "    \n",
    "    messages = s.split(splitter)[1:]  # Skip the homework itself (number 0)\n",
    "    for message in messages:\n",
    "        first = max(0, message.find('days ago')+9)\n",
    "        last  = message.find('\\nhelpful! ')        \n",
    "        \n",
    "        grade = ''\n",
    "        for emoji in cool:\n",
    "            if emoji in message:\n",
    "                grade = 'good'\n",
    "        for emoji in rejected:\n",
    "            if emoji in message:\n",
    "                grade = 'bad'\n",
    "        for name in people_piazza.name:        \n",
    "            if name in message:\n",
    "                df_piazza = df_piazza.append({'name': name, 'work':title, 'grade':grade,\n",
    "                                              'message':message[first:last]}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at one student\n",
    "\n",
    "q = df_piazza[df_piazza.name.str.match('John')]\n",
    "q\n",
    "\n",
    "#for i in range(q.shape[0]):\n",
    "#    print(q.message.iloc[i], end='\\n---------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now summarize, then merge left on the full list of people\n",
    "\n",
    "df_piazza['good'] = df_piazza.grade.str.match('good')\n",
    "df_piazza['bad']  = df_piazza.grade.str.match('bad')\n",
    "\n",
    "dfsp = (df_piazza        \n",
    "        .groupby(['name'])\n",
    "        .agg({'work':'count', 'good':'sum', 'bad':'sum'})\n",
    "        .reset_index()\n",
    "        .rename({'work':'total'}, axis=1)\n",
    "       )\n",
    "dfsp = (people_piazza\n",
    "        .merge(dfsp, on='name', how='left')\n",
    "       )\n",
    "\n",
    "dfsp.loc[dfsp.total.isna(), ['total', 'good', 'bad']] = 0\n",
    "dfsp.total = dfsp.total.astype(int)\n",
    "dfsp.good  = dfsp.good.astype(int)\n",
    "dfsp.bad   = dfsp.bad.astype(int)\n",
    "\n",
    "# dfsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One student\n",
    "dfsp[dfsp.name.str.match('John')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Full output\n",
    "\n",
    "df_full = dfsp.merge(dfs, on='email', suffixes=['_piazza','_zoom'])\n",
    "with pd.option_context('display.max_rows', 14000, 'display.width', 1000):\n",
    "    # print(df_full)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many missed assignments are problematic?\n",
    "# For Neuro this semester we seem to have 34 classes and 21 homework\n",
    "\n",
    "print('Can miss classes, and still pass:', 0.2*34)\n",
    "print('Can miss classes, and still get a B:', 0.1*34)\n",
    "print('Can miss homeworks, and still pass:', 0.2*21)\n",
    "print('Can miss homeworks, and still get a B:', 0.1*21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At-risk students\n",
    "\n",
    "classes_so_far = 17\n",
    "works_so_far = 10\n",
    "df_at_risk = df_full.query('total-bad < @works_so_far-1 | check < @classes_so_far-3')\n",
    "\n",
    "# print(','.join([e for e in df_at_risk.email]))\n",
    "#df_at_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grades\n",
    "\n",
    "df_full['grade'] = 'B'\n",
    "df_full.grade = df_full.grade.where(~(df_full.check < classes_so_far-3), 'C')\n",
    "df_full.grade = df_full.grade.where(~(df_full.check < classes_so_far-6), 'F')\n",
    "df_full.grade = df_full.grade.where(~(df_full.total < works_so_far-2), 'C')\n",
    "df_full.grade = df_full.grade.where(~(df_full.total < works_so_far-4), 'F')\n",
    "df_full.grade = df_full.grade.where(~((df_full.good > 2) & (df_full.grade=='B')), 'A')\n",
    "df_full.grade = df_full.grade.where(~((df_full.good > 1) & (df_full.grade=='B')), 'B+')\n",
    "#df_full.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(df_full, df_piazza, i):\n",
    "    # Write a full response for one student\n",
    "    \n",
    "    sec = df_full.iloc[i]\n",
    "    name = sec.name_piazza\n",
    "    \n",
    "    missing_work = (df_piazza\n",
    "                  .groupby(['work', 'name'])\n",
    "                  .agg({'message':'count'})\n",
    "                  .reset_index()\n",
    "                  .pivot_table(index='work', columns='name', values='message')\n",
    "                  .reset_index()\n",
    "                  [['work', name]]\n",
    "                  .set_axis(['work', 'name'], axis=1, inplace=False)\n",
    "                  .query('name.isna()', engine='python')\n",
    "                  .work\n",
    "                  .tolist()\n",
    "                 )\n",
    "    \n",
    "    def remove_double_spaces(s):\n",
    "        s = s.replace('\\n', ' ')\n",
    "        return ' '.join([c for c in s.split(' ') if c])\n",
    "    \n",
    "    print(f\"Dear {sec.name_piazza.split()[0]},\")\n",
    "    print(f\"you have attended {np.round(sec.check).astype(int)} classes \", end='')\n",
    "    print(f\"(out of {classes_so_far} that we had so far), \")\n",
    "    print(f\"and submitted {sec.total} homeworks (out of {works_so_far} that we had)\")   \n",
    "    if sec.good>0:\n",
    "        print(f\"{sec.good} of these homeworks were really good!! (and others were also fine :)\")\n",
    "    if sec.total < works_so_far:\n",
    "        print(f\"(Works that are missing: {'; '.join(missing_work)})\")\n",
    "    print(f\"With this in mind, your current technically projected grade is {sec.grade}\")\n",
    "    if sec.total < works_so_far:\n",
    "        message = \"\"\"If you want to improve, you can submit missing homeworks. \n",
    "              For missed lab work, just do the lab, and submit your work, as described in the assignment. \n",
    "              For missed questions, at this point the assignment is a bit different.\n",
    "              You will need to answer the following question: \n",
    "              'What is the most interesting thing that you learned that week,Â and what makes it interesting to you?''. \n",
    "              I would expect about a paragraph of text, with explicit references to what you learned from \n",
    "              videos and readings, and to what we discussed in class. AdditionalÂ sources are also welcome!\"\"\"\n",
    "        print(remove_double_spaces(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.where(df_full.name_piazza.str.match('Ell'))[0][0]\n",
    "response(df_full, df_piazza, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(df_full.shape[0]):\n",
    "    response(df_full, df_piazza, i)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ouput the summary csv\n",
    "#recognized.to_csv(folder_name + '../attendance_summary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
