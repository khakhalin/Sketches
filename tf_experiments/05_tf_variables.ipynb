{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Variables and matrix operations\n",
    "\n",
    "* Intro: https://www.tensorflow.org/guide/variable\n",
    "* Definitions: https://www.tensorflow.org/api_docs/python/tf/Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `trainable` to false if this variable shouldn't participate in automatic gradient calculations. Example: a loop counter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Fantasy:0' shape=(2,) dtype=float32, numpy=array([0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.Variable([0.0, 1.0], name='Fantasy', trainable=False)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinAlg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a= <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.0>\n",
      "b= <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([2.], dtype=float32)>\n",
      "c= [3.]\n"
     ]
    }
   ],
   "source": [
    "# Does tf recognize that scalar and 0-vector are the same? Yes.\n",
    "\n",
    "a = tf.Variable(1.0)\n",
    "b = tf.Variable([2.0])\n",
    "\n",
    "print('a=',a)\n",
    "print('b=', b)\n",
    "c = tf.Variable(a+b)\n",
    "print('c=', c.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a= <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=1>\n",
      "b= <tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([2.], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([3.], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# What if number types are different? We need to convert them.\n",
    "\n",
    "a = tf.Variable(1)\n",
    "b = tf.Variable([2.0])\n",
    "\n",
    "print('a=',a)\n",
    "print('b=', b)\n",
    "print(tf.Variable(tf.cast(a, tf.float32)+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a= <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=1.0>\n",
      "b= <tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([2., 1.], dtype=float32)>\n",
      "c= <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[ 0.,  1.],\n",
      "       [ 1., -1.]], dtype=float32)>\n",
      "a+b= <tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([3., 2.], dtype=float32)>\n",
      "a+c= <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[1., 2.],\n",
      "       [2., 0.]], dtype=float32)>\n",
      "b+c= <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[2., 2.],\n",
      "       [3., 0.]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# Does it broadcast dimensions? Yes!\n",
    "a = tf.Variable(1.0)\n",
    "b = tf.Variable([2.0, 1.0])\n",
    "c = tf.Variable([[0.0, 1.0], [1.0, -1.0]])\n",
    "\n",
    "print('a=',a)\n",
    "print('b=', b)\n",
    "print('c=', c)\n",
    "print('a+b=', tf.Variable(a+b))\n",
    "print('a+c=', tf.Variable(a+c))\n",
    "print('b+c=', tf.Variable(b+c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([1., 2.], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([1., 2.], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# As in numpy, 1-vectors aren't quite matrices.\n",
    "# Note tho that they seem to be more column-like (2,) than row-like.\n",
    "print(tf.Variable(            ([1.0, 2.0])))\n",
    "print(tf.Variable(tf.transpose([1.0, 2.0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
      "array([[1.],\n",
      "       [2.]], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[1., 2.]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# We can force the columness. And then transposition immediately makes sense\n",
    "a = tf.Variable(tf.transpose([[1.0, 2.0]]))\n",
    "print(a)\n",
    "print(tf.Variable(tf.transpose(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a*b= tf.Tensor(\n",
      "[[ 0  2]\n",
      " [-3  0]], shape=(2, 2), dtype=int32) - Elementwise multiplication with broadcasting.\n",
      "b*a= tf.Tensor(\n",
      "[[ 0  2]\n",
      " [-3  0]], shape=(2, 2), dtype=int32) - ...is symmetric obviously\n",
      "a times b= tf.Tensor(\n",
      "[[-2  1]\n",
      " [-4  3]], shape=(2, 2), dtype=int32)\n",
      "b times a= tf.Tensor(\n",
      "[[ 3  4]\n",
      " [-1 -2]], shape=(2, 2), dtype=int32)\n",
      "a @ b= tf.Tensor(\n",
      "[[-2  1]\n",
      " [-4  3]], shape=(2, 2), dtype=int32) - same as tf.matmul()\n",
      "aprime times b= tf.Tensor(\n",
      "[[-3  1]\n",
      " [-4  2]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable([[1,2], [3,4]])\n",
    "b = tf.Variable([[0,1], [-1, 0]])\n",
    "print('a*b=', a * b, '- Elementwise multiplication with broadcasting.')\n",
    "print('b*a=', b * a, '- ...is symmetric obviously')\n",
    "print('a times b=',tf.matmul(a,b))\n",
    "print('b times a=', tf.matmul(b,a))\n",
    "print('a @ b=', a @ b, '- same as tf.matmul()')\n",
    "print('aprime times b=', tf.matmul(a, b, transpose_a=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner and outer products of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For some reason both matmult, tensordot, and einsum crash the GPU and kill the kernel\n",
    "# if I try to do inner or outer product of vectors.\n",
    "# All other matrix operations (with non-vector matrices) work!\n",
    "\n",
    "a = tf.Variable([1.0, 2.0])\n",
    "b = tf.Variable(a)\n",
    "# print('b dot a=', tf.matmul(a, b, transpose_a=True))\n",
    "\n",
    "# Returns: Blas GEMM launch failed : a.shape=(1, 2), b.shape=(1, 2), m=2, n=2, k=1 [Op:MatMul]\n",
    "# Then hangs and kills the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer product= tf.Tensor(\n",
      "[[1. 2.]\n",
      " [2. 4.]], shape=(2, 2), dtype=float32)\n",
      "inner product= tf.Tensor([[5.]], shape=(1, 1), dtype=float32)\n",
      "dotproduct= tf.Tensor(\n",
      "[[1. 2.]\n",
      " [2. 4.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# It works on a CPU:\n",
    "\n",
    "with tf.device('CPU:0'):\n",
    "    a = tf.Variable([[1.0, 2.0]])\n",
    "    b = tf.Variable(a)\n",
    "    print('outer product=', tf.matmul(a, b, transpose_a=True))\n",
    "    print('inner product=', tf.matmul(a, b, transpose_b=True))\n",
    "    \n",
    "    a = tf.Variable([1.0, 2.0])\n",
    "    b = tf.Variable(a)\n",
    "    print('dotproduct=', tf.tensordot(a, b, axes=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a= <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[1., 2.]], dtype=float32)>\n",
      "b= <tf.Variable 'Variable:0' shape=(1, 2) dtype=float32, numpy=array([[1., 2.]], dtype=float32)>\n",
      "inner: tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "outer: tf.Tensor(\n",
      "[[1. 2.]\n",
      " [2. 4.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Versions that don't crash the GPU (with elementwise operations)\n",
    "# With matrix vectors (1,2)\n",
    "\n",
    "a = tf.Variable([[1.0, 2.0]])\n",
    "b = tf.Variable(a)\n",
    "print('a=', a)\n",
    "print('b=', b)\n",
    "print('inner:', tf.reduce_sum(a*b))\n",
    "print('outer:', a*tf.transpose(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a= <tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([1., 2.], dtype=float32)>\n",
      "b= <tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([1., 2.], dtype=float32)>\n",
      "inner: tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "outer: tf.Tensor([1. 4.], shape=(2,), dtype=float32) - doesn't work in this case as transpose doesn't aply to flat vectors\n",
      "broadcasted outer: tf.Tensor(\n",
      "[[1. 2.]\n",
      " [2. 4.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Same, but with vector vectors ( ,2)\n",
    "\n",
    "a = tf.Variable([1.0, 2.0])\n",
    "b = tf.Variable(a)\n",
    "print('a=', a)\n",
    "print('b=', b)\n",
    "print('inner:', tf.reduce_sum(a*b))\n",
    "print('outer:', a*tf.transpose(b), \"- doesn't work in this case as transpose doesn't aply to flat vectors\")\n",
    "print('broadcasted outer:', a[None,:]*b[:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 2 -1]\n",
      " [ 4 -3]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 3 -1]\n",
      " [ 4 -2]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 0  3]\n",
      " [-7  0]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 0  4]\n",
      " [-6  0]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor([-1 -1], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Einstein notation.\n",
    "# Still for some reason crashes for vectors-as-matrices :(\n",
    "# But works for non-singleton-dimensioned matrices!\n",
    "\n",
    "a = tf.Variable([[1,2], [3,4]])\n",
    "b = tf.Variable([[0,1], [-1, 0]])\n",
    "print(tf.einsum('ji,ki->jk', a, b))\n",
    "print(tf.einsum('ij,ki->jk', a, b))\n",
    "print(tf.einsum('ji,jk->jk', a, b))\n",
    "print(tf.einsum('ij,jk->jk', a, b))\n",
    "print(tf.einsum('ji,ik->j', a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.Variable([1.0, 2.0])\n",
    "# tf.einsum('ijk,ijk->ik', a[None,:,None], a[None,:,None])\n",
    "\n",
    "# This still hangs the GPU. Even with broadcasting, it still does it :((("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
